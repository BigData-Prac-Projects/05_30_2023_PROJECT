


scp /Users/shanthanreddydondapaati/Downloads/UK_Accidents_10_years_history_with_many_variables/Casualties0514.csv bigdatacloudxlab27228@f.cloudxlab.com:/home/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_data

----------

hadoop fs -put SRD_05312023_UK_Accidents_data/Casualties0514.csv /user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_Landing

----------

HIVE:

show databases;

use srd_05212023_uk_accidents_hive_db;

show tables;

select * from uk_accidents limit 5;


CREATE EXTERNAL TABLE IF NOT EXISTS uk_accidents (
  Accident_Index STRING,
  Vehicle_Reference INT,
  Casualty_Reference INT,
  Casualty_Class INT,
  Sex_of_Casualty INT,
  Age_of_Casualty INT,
  Age_Band_of_Casualty INT,
  Casualty_Severity INT,
  Pedestrian_Location INT,
  Pedestrian_Movement INT,
  Car_Passenger INT,
  Bus_or_Coach_Passenger INT,
  Pedestrian_Road_Maintenance_Worker INT,
  Casualty_Type INT,
  Casualty_Home_Area_Type INT
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES ("separatorChar" = ",","quoteChar" = "\"","escapeChar" = "\\")
STORED AS TEXTFILE
LOCATION '/user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_Landing';

-----------------------------------------------------------------------------------------------

pyspark
spark = SparkSession.builder().appName("YourAppName").enableHiveSupport().getOrCreate()
spark.sql("USE srd_05212023_uk_accidents_hive_db")
spark.sql("show tables").show()
hive_df = spark.sql("select * from uk_accidents ").show()
hive_df = spark.sql("SELECT * FROM uk_accidents WHERE Accident_Index != 'Accident_Index'").show()
replaced_df = hive_df.na.replace('', 'N/A').show()

-----------------------------------------------------------------------------------------------

hdfs dfs -mkdir /user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_Curated

replaced_df.write.mode("overwrite").parquet("/user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_Curated")

hdfs dfs -du /user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_Curated

-----------------------------------------------------------------------------------------------

mysql:

use sqoopex 


CREATE TABLE SRD_06022023_UK_Accidents_SQOOP
(Accident_Index VARCHAR(255),
  Vehicle_Reference INT,
  Casualty_Reference INT,
  Casualty_Class INT,
  Sex_of_Casualty INT,
  Age_of_Casualty INT,
  Age_Band_of_Casualty INT,
  Casualty_Severity INT,
  Pedestrian_Location INT,
  Pedestrian_Movement INT,
  Car_Passenger INT,
  Bus_or_Coach_Passenger INT,
  Pedestrian_Road_Maintenance_Worker INT,
  Casualty_Type INT,
  Casualty_Home_Area_Type INT)
;

DESCRIBE sqoopex.SRD_06022023_UK_Accidents_SQOOP;


sqoop export --connect jdbc:mysql://cxln2:3306/sqoopex --username sqoopuser --password NHkkP876rp --table SRD_06022023_UK_Accidents_SQOOP --export-dir hdfs://cxln1.c.thelab-240901.internal:8020/user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_Curated_CSV/part-00002-6cfd76c6-f890-4377-9619-67db0fe61548.csv --input-fields-terminated-by ',' --input-lines-terminated-by '\n'

mysql: use sqoopex

select * from SRD_06022023_UK_Accidents_SQOOP limit 10;

-----------------------------------------------------------------------------------------------

nano UK_Accidents_AUTO.sh 


chmod +x UK_Accidents_AUTO.sh 


./UK_Accidents_AUTO.sh


-----------------------------------------------------------------------------------------------

hadoop fs -get /user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_Landing/Casualties0514.csv /home/bigdatacloudxlab27228/SRD_05312023_UK_Accidents
hadoop fs -put /user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents/Casualties0514.csv /home/bigdatacloudxlab27228/SRD_05312023_UK_Accidents

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------

rsync -avz /Users/shanthanreddydondapaati/Downloads/UK_Accidents_10_years_history_with_many_variables/Casualties0514.csv bigdatacloudxlab27228@cloudxlab.com:/home/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_data

sftp bigdatacloudxlab27228@cloudxlab.com
put /Users/shanthanreddydondapaati/Downloads/UK_Accidents_10_years_history_with_many_variables/Casualties0514.csv /home/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_data


CREATE EXTERNAL TABLE IF NOT EXISTS uk_accidents (
  Accident_Index STRING,
  Vehicle_Reference INT,
  Casualty_Reference INT,
  Casualty_Class INT,
  Sex_of_Casualty INT,
  Age_of_Casualty INT,
  Age_Band_of_Casualty INT,
  Casualty_Severity INT,
  Pedestrian_Location INT,
  Pedestrian_Movement INT,
  Car_Passenger INT,
  Bus_or_Coach_Passenger INT,
  Pedestrian_Road_Maintenance_Worker INT,
  Casualty_Type INT,
  Casualty_Home_Area_Type INT
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
LOCATION '/user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_Landing/'
TBLPROPERTIES ('skip.header.line.count'='1');

sqoop export \
--connect jdbc:mysql://<mysql_host>:<mysql_port>/<database> \
--username <username> \
--password <password> \
--table <table_name> \
--export-dir /user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_Curated \
--input-fields-terminated-by '\t'


sqoop export --connect jdbc:mysql://cxln2:3306/sqoopex --username sqoopuser --password NHkkP876rp --table SRD_06022023_UK_Accidents --export-dir /user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_Curated --input-fields-terminated-by '|' --input-lines-terminated-by '\n' --m 1

sqoop export \
--connect jdbc:mysql://<mysql_host>:<mysql_port>/<database> \
--username <username> \
--password <password> \
--table <table_name> \
--export-dir /user/bigdatacloudxlab27228/SRD_05312023_UK_Accidents_Curated \
--driver com.mysql.jdbc.Driver

